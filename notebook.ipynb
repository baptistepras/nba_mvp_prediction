{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa9d5f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing all modules\n",
    "\n",
    "\n",
    "import sys\n",
    "import scripts_raw_data.fetch_raw_data as r\n",
    "import scripts_raw_data.map_team_names as b\n",
    "import scripts_data_process.build_allStats_from1980 as p\n",
    "import scripts_data_process.build_splits as bs\n",
    "import train_models as t\n",
    "import hyperparameters_tuning.greedy_forward_feature_selection as gf\n",
    "import hyperparameters_tuning.greedy_backward_feature_selection as gb\n",
    "import hyperparameters_tuning.hyperparameters_tuner as ht\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef7af2c",
   "metadata": {},
   "source": [
    "# I. Fetching the raw data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef14725e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[INFO] Downloading per-season raw data\n",
      "[INFO] Downloading season 1980 from https://www.basketball-reference.com/leagues/NBA_1980_per_game.html...\n",
      "[SKIP] Skipping season 1980, file already exists.\n",
      "[INFO] Downloading season 1981 from https://www.basketball-reference.com/leagues/NBA_1981_per_game.html...\n",
      "[SKIP] Skipping season 1981, file already exists.\n",
      "[INFO] Downloading season 1982 from https://www.basketball-reference.com/leagues/NBA_1982_per_game.html...\n",
      "[SKIP] Skipping season 1982, file already exists.\n",
      "[INFO] Downloading season 1983 from https://www.basketball-reference.com/leagues/NBA_1983_per_game.html...\n",
      "[SKIP] Skipping season 1983, file already exists.\n",
      "[INFO] Downloading season 1984 from https://www.basketball-reference.com/leagues/NBA_1984_per_game.html...\n",
      "[SKIP] Skipping season 1984, file already exists.\n",
      "[INFO] Downloading season 1985 from https://www.basketball-reference.com/leagues/NBA_1985_per_game.html...\n",
      "[SKIP] Skipping season 1985, file already exists.\n",
      "[INFO] Downloading season 1986 from https://www.basketball-reference.com/leagues/NBA_1986_per_game.html...\n",
      "[SKIP] Skipping season 1986, file already exists.\n",
      "[INFO] Downloading season 1987 from https://www.basketball-reference.com/leagues/NBA_1987_per_game.html...\n",
      "[SKIP] Skipping season 1987, file already exists.\n",
      "[INFO] Downloading season 1988 from https://www.basketball-reference.com/leagues/NBA_1988_per_game.html...\n",
      "[SKIP] Skipping season 1988, file already exists.\n",
      "[INFO] Downloading season 1989 from https://www.basketball-reference.com/leagues/NBA_1989_per_game.html...\n",
      "[SKIP] Skipping season 1989, file already exists.\n",
      "[INFO] Downloading season 1990 from https://www.basketball-reference.com/leagues/NBA_1990_per_game.html...\n",
      "[SKIP] Skipping season 1990, file already exists.\n",
      "[INFO] Downloading season 1991 from https://www.basketball-reference.com/leagues/NBA_1991_per_game.html...\n",
      "[SKIP] Skipping season 1991, file already exists.\n",
      "[INFO] Downloading season 1992 from https://www.basketball-reference.com/leagues/NBA_1992_per_game.html...\n",
      "[SKIP] Skipping season 1992, file already exists.\n",
      "[INFO] Downloading season 1993 from https://www.basketball-reference.com/leagues/NBA_1993_per_game.html...\n",
      "[SKIP] Skipping season 1993, file already exists.\n",
      "[INFO] Downloading season 1994 from https://www.basketball-reference.com/leagues/NBA_1994_per_game.html...\n",
      "[SKIP] Skipping season 1994, file already exists.\n",
      "[INFO] Downloading season 1995 from https://www.basketball-reference.com/leagues/NBA_1995_per_game.html...\n",
      "[SKIP] Skipping season 1995, file already exists.\n",
      "[INFO] Downloading season 1996 from https://www.basketball-reference.com/leagues/NBA_1996_per_game.html...\n",
      "[SKIP] Skipping season 1996, file already exists.\n",
      "[INFO] Downloading season 1997 from https://www.basketball-reference.com/leagues/NBA_1997_per_game.html...\n",
      "[SKIP] Skipping season 1997, file already exists.\n",
      "[INFO] Downloading season 1998 from https://www.basketball-reference.com/leagues/NBA_1998_per_game.html...\n",
      "[SKIP] Skipping season 1998, file already exists.\n",
      "[INFO] Downloading season 1999 from https://www.basketball-reference.com/leagues/NBA_1999_per_game.html...\n",
      "[SKIP] Skipping season 1999, file already exists.\n",
      "[INFO] Downloading season 2000 from https://www.basketball-reference.com/leagues/NBA_2000_per_game.html...\n",
      "[SKIP] Skipping season 2000, file already exists.\n",
      "[INFO] Downloading season 2001 from https://www.basketball-reference.com/leagues/NBA_2001_per_game.html...\n",
      "[SKIP] Skipping season 2001, file already exists.\n",
      "[INFO] Downloading season 2002 from https://www.basketball-reference.com/leagues/NBA_2002_per_game.html...\n",
      "[SKIP] Skipping season 2002, file already exists.\n",
      "[INFO] Downloading season 2003 from https://www.basketball-reference.com/leagues/NBA_2003_per_game.html...\n",
      "[SKIP] Skipping season 2003, file already exists.\n",
      "[INFO] Downloading season 2004 from https://www.basketball-reference.com/leagues/NBA_2004_per_game.html...\n",
      "[SKIP] Skipping season 2004, file already exists.\n",
      "[INFO] Downloading season 2005 from https://www.basketball-reference.com/leagues/NBA_2005_per_game.html...\n",
      "[SKIP] Skipping season 2005, file already exists.\n",
      "[INFO] Downloading season 2006 from https://www.basketball-reference.com/leagues/NBA_2006_per_game.html...\n",
      "[SKIP] Skipping season 2006, file already exists.\n",
      "[INFO] Downloading season 2007 from https://www.basketball-reference.com/leagues/NBA_2007_per_game.html...\n",
      "[SKIP] Skipping season 2007, file already exists.\n",
      "[INFO] Downloading season 2008 from https://www.basketball-reference.com/leagues/NBA_2008_per_game.html...\n",
      "[SKIP] Skipping season 2008, file already exists.\n",
      "[INFO] Downloading season 2009 from https://www.basketball-reference.com/leagues/NBA_2009_per_game.html...\n",
      "[SKIP] Skipping season 2009, file already exists.\n",
      "[INFO] Downloading season 2010 from https://www.basketball-reference.com/leagues/NBA_2010_per_game.html...\n",
      "[SKIP] Skipping season 2010, file already exists.\n",
      "[INFO] Downloading season 2011 from https://www.basketball-reference.com/leagues/NBA_2011_per_game.html...\n",
      "[SKIP] Skipping season 2011, file already exists.\n",
      "[INFO] Downloading season 2012 from https://www.basketball-reference.com/leagues/NBA_2012_per_game.html...\n",
      "[SKIP] Skipping season 2012, file already exists.\n",
      "[INFO] Downloading season 2013 from https://www.basketball-reference.com/leagues/NBA_2013_per_game.html...\n",
      "[SKIP] Skipping season 2013, file already exists.\n",
      "[INFO] Downloading season 2014 from https://www.basketball-reference.com/leagues/NBA_2014_per_game.html...\n",
      "[SKIP] Skipping season 2014, file already exists.\n",
      "[INFO] Downloading season 2015 from https://www.basketball-reference.com/leagues/NBA_2015_per_game.html...\n",
      "[SKIP] Skipping season 2015, file already exists.\n",
      "[INFO] Downloading season 2016 from https://www.basketball-reference.com/leagues/NBA_2016_per_game.html...\n",
      "[SKIP] Skipping season 2016, file already exists.\n",
      "[INFO] Downloading season 2017 from https://www.basketball-reference.com/leagues/NBA_2017_per_game.html...\n",
      "[SKIP] Skipping season 2017, file already exists.\n",
      "[INFO] Downloading season 2018 from https://www.basketball-reference.com/leagues/NBA_2018_per_game.html...\n",
      "[SKIP] Skipping season 2018, file already exists.\n",
      "[INFO] Downloading season 2019 from https://www.basketball-reference.com/leagues/NBA_2019_per_game.html...\n",
      "[SKIP] Skipping season 2019, file already exists.\n",
      "[INFO] Downloading season 2020 from https://www.basketball-reference.com/leagues/NBA_2020_per_game.html...\n",
      "[SKIP] Skipping season 2020, file already exists.\n",
      "[INFO] Downloading season 2021 from https://www.basketball-reference.com/leagues/NBA_2021_per_game.html...\n",
      "[SKIP] Skipping season 2021, file already exists.\n",
      "[INFO] Downloading season 2022 from https://www.basketball-reference.com/leagues/NBA_2022_per_game.html...\n",
      "[SKIP] Skipping season 2022, file already exists.\n",
      "[INFO] Downloading season 2023 from https://www.basketball-reference.com/leagues/NBA_2023_per_game.html...\n",
      "[SKIP] Skipping season 2023, file already exists.\n",
      "[INFO] Downloading season 2024 from https://www.basketball-reference.com/leagues/NBA_2024_per_game.html...\n",
      "[SKIP] Skipping season 2024, file already exists.\n",
      "[INFO] Downloading season 2025 from https://www.basketball-reference.com/leagues/NBA_2025_per_game.html...\n",
      "[SKIP] Skipping season 2025, file already exists.\n",
      "[DONE] Saved raw data to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\raw_data\\raw_player_csv\n",
      "\n",
      "[INFO] Downloading expanded standings for each season\n",
      "[INFO] Downloading expanded standings for 1980...\n",
      "[SKIP] Skipping 1980, already exists.\n",
      "[INFO] Downloading expanded standings for 1981...\n",
      "[SKIP] Skipping 1981, already exists.\n",
      "[INFO] Downloading expanded standings for 1982...\n",
      "[SKIP] Skipping 1982, already exists.\n",
      "[INFO] Downloading expanded standings for 1983...\n",
      "[SKIP] Skipping 1983, already exists.\n",
      "[INFO] Downloading expanded standings for 1984...\n",
      "[SKIP] Skipping 1984, already exists.\n",
      "[INFO] Downloading expanded standings for 1985...\n",
      "[SKIP] Skipping 1985, already exists.\n",
      "[INFO] Downloading expanded standings for 1986...\n",
      "[SKIP] Skipping 1986, already exists.\n",
      "[INFO] Downloading expanded standings for 1987...\n",
      "[SKIP] Skipping 1987, already exists.\n",
      "[INFO] Downloading expanded standings for 1988...\n",
      "[SKIP] Skipping 1988, already exists.\n",
      "[INFO] Downloading expanded standings for 1989...\n",
      "[SKIP] Skipping 1989, already exists.\n",
      "[INFO] Downloading expanded standings for 1990...\n",
      "[SKIP] Skipping 1990, already exists.\n",
      "[INFO] Downloading expanded standings for 1991...\n",
      "[SKIP] Skipping 1991, already exists.\n",
      "[INFO] Downloading expanded standings for 1992...\n",
      "[SKIP] Skipping 1992, already exists.\n",
      "[INFO] Downloading expanded standings for 1993...\n",
      "[SKIP] Skipping 1993, already exists.\n",
      "[INFO] Downloading expanded standings for 1994...\n",
      "[SKIP] Skipping 1994, already exists.\n",
      "[INFO] Downloading expanded standings for 1995...\n",
      "[SKIP] Skipping 1995, already exists.\n",
      "[INFO] Downloading expanded standings for 1996...\n",
      "[SKIP] Skipping 1996, already exists.\n",
      "[INFO] Downloading expanded standings for 1997...\n",
      "[SKIP] Skipping 1997, already exists.\n",
      "[INFO] Downloading expanded standings for 1998...\n",
      "[SKIP] Skipping 1998, already exists.\n",
      "[INFO] Downloading expanded standings for 1999...\n",
      "[SKIP] Skipping 1999, already exists.\n",
      "[INFO] Downloading expanded standings for 2000...\n",
      "[SKIP] Skipping 2000, already exists.\n",
      "[INFO] Downloading expanded standings for 2001...\n",
      "[SKIP] Skipping 2001, already exists.\n",
      "[INFO] Downloading expanded standings for 2002...\n",
      "[SKIP] Skipping 2002, already exists.\n",
      "[INFO] Downloading expanded standings for 2003...\n",
      "[SKIP] Skipping 2003, already exists.\n",
      "[INFO] Downloading expanded standings for 2004...\n",
      "[SKIP] Skipping 2004, already exists.\n",
      "[INFO] Downloading expanded standings for 2005...\n",
      "[SKIP] Skipping 2005, already exists.\n",
      "[INFO] Downloading expanded standings for 2006...\n",
      "[SKIP] Skipping 2006, already exists.\n",
      "[INFO] Downloading expanded standings for 2007...\n",
      "[SKIP] Skipping 2007, already exists.\n",
      "[INFO] Downloading expanded standings for 2008...\n",
      "[SKIP] Skipping 2008, already exists.\n",
      "[INFO] Downloading expanded standings for 2009...\n",
      "[SKIP] Skipping 2009, already exists.\n",
      "[INFO] Downloading expanded standings for 2010...\n",
      "[SKIP] Skipping 2010, already exists.\n",
      "[INFO] Downloading expanded standings for 2011...\n",
      "[SKIP] Skipping 2011, already exists.\n",
      "[INFO] Downloading expanded standings for 2012...\n",
      "[SKIP] Skipping 2012, already exists.\n",
      "[INFO] Downloading expanded standings for 2013...\n",
      "[SKIP] Skipping 2013, already exists.\n",
      "[INFO] Downloading expanded standings for 2014...\n",
      "[SKIP] Skipping 2014, already exists.\n",
      "[INFO] Downloading expanded standings for 2015...\n",
      "[SKIP] Skipping 2015, already exists.\n",
      "[INFO] Downloading expanded standings for 2016...\n",
      "[SKIP] Skipping 2016, already exists.\n",
      "[INFO] Downloading expanded standings for 2017...\n",
      "[SKIP] Skipping 2017, already exists.\n",
      "[INFO] Downloading expanded standings for 2018...\n",
      "[SKIP] Skipping 2018, already exists.\n",
      "[INFO] Downloading expanded standings for 2019...\n",
      "[SKIP] Skipping 2019, already exists.\n",
      "[INFO] Downloading expanded standings for 2020...\n",
      "[SKIP] Skipping 2020, already exists.\n",
      "[INFO] Downloading expanded standings for 2021...\n",
      "[SKIP] Skipping 2021, already exists.\n",
      "[INFO] Downloading expanded standings for 2022...\n",
      "[SKIP] Skipping 2022, already exists.\n",
      "[INFO] Downloading expanded standings for 2023...\n",
      "[SKIP] Skipping 2023, already exists.\n",
      "[INFO] Downloading expanded standings for 2024...\n",
      "[SKIP] Skipping 2024, already exists.\n",
      "[INFO] Downloading expanded standings for 2025...\n",
      "[SKIP] Skipping 2025, already exists.\n",
      "[DONE] Saved raw data to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\raw_data\\raw_standings_csv\n",
      "\n",
      "[INFO] All requested downloads finished.\n"
     ]
    }
   ],
   "source": [
    "r.main(1980, 2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1684a531",
   "metadata": {},
   "source": [
    "We build a mapping between the teams abbreviations and full team names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03dcf368",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Building team abbreviation mapping\n",
      "Scanning player CSVs for team IDs: 100%|██████████| 46/46 [00:00<00:00, 271.53it/s]\n",
      "[WARN] Unknown team abbreviations not found on site: ['2TM', '3TM', '4TM', '5TM', 'BRK', 'CHH', 'CHO', 'KCK', 'NOK', 'NOP', 'SDC', 'SEA', 'VAN', 'WSB']\n",
      "[ERROR] Run merge_team_mapping() to resolve them.\n",
      "[DONE] Saved mapping to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\raw_data\\team_id_to_name.csv\n",
      "\n",
      "[INFO] Fetching missing teams from historical_teams.csv\n",
      "[DONE] Merged mapping saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\raw_data\\team_id_to_name.csv\n",
      "\n",
      "[INFO] Checking for missing teams\n",
      "Checking player team IDs: 100%|██████████| 46/46 [00:00<00:00, 279.42it/s]\n",
      "[DONE] All team abbreviations in player stats are mapped.\n",
      "Checking standings team names: 100%|██████████| 46/46 [00:00<00:00, 537.74it/s]\n",
      "[DONE] All full team names in standings are mapped.\n",
      "\n",
      "[INFO] Checking for duplicate team IDs\n",
      "[DONE] No duplicate Team ID found in the mapping.\n",
      "\n",
      "[INFO] Checking mapping\n",
      "Validating player-to-standings mapping: 100%|██████████| 46/46 [00:00<00:00, 202.59it/s]\n",
      "[DONE] Finished checking player-to-standings mapping.\n"
     ]
    }
   ],
   "source": [
    "b.main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddb7559",
   "metadata": {},
   "source": [
    "# II. Data processing. \n",
    "\n",
    "\n",
    "We construct per season (year) player datasets, collecting all basic player statistics available since 1980 (e.g., G / GS / MP / FG / FGA / FG% / 3P / 3PA / 3P% / 2P / 2PA / 2P% / eFG%,\n",
    "FT / FTA / FT% / ORB / DRB / TRB / STL / BLK / TOV / PF / AST / PTS), and enriching them with team context: team rank, win-loss differential, and one-hot position encoding. We prepare aligned inputs and labels (top-1, top-10 MVP) for downstream MVP prediction tasks. We build the following files : Data.csv (features per player), Y_top1.csv (binary label: MVP or not), Y_top10.csv (MVP-rank or -1), and Name.csv (player names), all aligned row-by-row. Each file is then stored in processed_data/allStats_from1980/year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e55a82e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running pipeline from 1980 to 2025...\n",
      "\n",
      "[INFO] Processing the raw data to per-season cleaned data\n",
      "Creating per-season cleaned data: 100%|██████████| 46/46 [00:05<00:00,  8.98it/s]\n",
      "[DONE] Saved per-season data to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\processed_data\\allStats_from1980\n",
      "\n",
      "[INFO] Filling missing values for per-season data\n",
      "Imputing missing values with KNN: 100%|██████████| 46/46 [00:01<00:00, 25.55it/s]\n",
      "[DONE] Finished filling missing values.\n",
      "\n",
      "[INFO] Normalizing per-season data\n",
      "Normalizing cleaned stats: 100%|██████████| 46/46 [00:01<00:00, 28.46it/s]\n",
      "[DONE] Finished normalization.\n",
      "\n",
      "[INFO] Verifying processed data integrity\n",
      "Validating per-season files: 100%|██████████| 46/46 [00:00<00:00, 59.78it/s]\n",
      "[DONE] Finished checking processed data integrity.\n"
     ]
    }
   ],
   "source": [
    "p.main(1980, 2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0062474",
   "metadata": {},
   "source": [
    "We build loso (leave one season out) splits from the processed data. The files are stored in datasets/allStats_from1980/year/train for train data (and datasets/allStats_from1980/year/test for test data). For one year, say 2025, the train files contains the data of all years except 2025 and the test file contains the data from 2025. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f4338b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Creating LOSO splits for pipeline 'allStats_from1980' from 1980 to 2025...\n",
      "\n",
      "[INFO] Creating leave-one-season-out splits for pipeline 'allStats_from1980'\n",
      "Building LOSO splits: 100%|██████████| 46/46 [00:19<00:00,  2.40it/s]\n",
      "[DONE] Finished creating LOSO splits for pipeline 'allStats_from1980'\n",
      "[INFO] Checking LOSO splits for pipeline 'allStats_from1980' from 1980 to 2025...\n",
      "\n",
      "[INFO] Checking LOSO splits integrity for pipeline 'allStats_from1980'\n",
      "Checking splits: 100%|██████████| 46/46 [00:02<00:00, 22.11it/s]\n",
      "[DONE] All LOSO splits are consistent for pipeline 'allStats_from1980'\n",
      "\n",
      "[INFO] All selected pipelines finished.\n"
     ]
    }
   ],
   "source": [
    "bs.main([\"all1980\"], 1980, 2025)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee4133b",
   "metadata": {},
   "source": [
    "# III. Training the models.\n",
    "\n",
    "We chose to train the following models : logistic regression, random forest, and xgb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf2edc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{'pipeline': ['all1980'], 'model': 'logreg', 'start': 1980, 'end': 2025, 'verbose': False, 'full': False, 'datasets_base_dir': 'c:\\\\Users\\\\cleme\\\\Eloi\\\\Code\\\\HoML\\\\Projet-Homl\\\\datasets', 'models_base_dir': 'c:\\\\Users\\\\cleme\\\\Eloi\\\\Code\\\\HoML\\\\Projet-Homl\\\\models', 'vprint': <function main.<locals>.<lambda> at 0x000001A76B5B20E0>, 'model_class': <class 'sklearn.linear_model._logistic.LogisticRegression'>, 'model_name': 'LogisticRegression', 'pipelines_to_run': ['all1980'], 'p': 'all1980', 'pipeline_key': 'all1980', 'pipeline_name': 'allStats_from1980', 'pipeline_min_year': 1980, 'frame': <frame at 0x000001A768C84B40, file 'c:\\\\Users\\\\cleme\\\\Eloi\\\\Code\\\\HoML\\\\Projet-Homl\\\\train_models.py', line 502, code main>}\n",
      "[INFO] Running model 'LogisticRegression' on pipeline 'allStats_from1980' from 1980 to 2025...\n",
      "[INFO] Using hyperparameters: {'solver': 'saga', 'penalty': 'l2', 'class_weight': None, 'max_iter': 50000, 'C': 5.0}\n",
      "\n",
      "[INFO] Training model for year 1980...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_1980.joblib\n",
      "\n",
      "[INFO] Training model for year 1981...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_1981.joblib\n",
      "\n",
      "[INFO] Training model for year 1982...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_1982.joblib\n",
      "\n",
      "[INFO] Training model for year 1983...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_1983.joblib\n",
      "\n",
      "[INFO] Training model for year 1984...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_1984.joblib\n",
      "\n",
      "[INFO] Training model for year 1985...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_1985.joblib\n",
      "\n",
      "[INFO] Training model for year 1986...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_1986.joblib\n",
      "\n",
      "[INFO] Training model for year 1987...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_1987.joblib\n",
      "\n",
      "[INFO] Training model for year 1988...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_1988.joblib\n",
      "\n",
      "[INFO] Training model for year 1989...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_1989.joblib\n",
      "\n",
      "[INFO] Training model for year 1990...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_1990.joblib\n",
      "\n",
      "[INFO] Training model for year 1991...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_1991.joblib\n",
      "\n",
      "[INFO] Training model for year 1992...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_1992.joblib\n",
      "\n",
      "[INFO] Training model for year 1993...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_1993.joblib\n",
      "\n",
      "[INFO] Training model for year 1994...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_1994.joblib\n",
      "\n",
      "[INFO] Training model for year 1995...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_1995.joblib\n",
      "\n",
      "[INFO] Training model for year 1996...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_1996.joblib\n",
      "\n",
      "[INFO] Training model for year 1997...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_1997.joblib\n",
      "\n",
      "[INFO] Training model for year 1998...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_1998.joblib\n",
      "\n",
      "[INFO] Training model for year 1999...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_1999.joblib\n",
      "\n",
      "[INFO] Training model for year 2000...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_2000.joblib\n",
      "\n",
      "[INFO] Training model for year 2001...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_2001.joblib\n",
      "\n",
      "[INFO] Training model for year 2002...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_2002.joblib\n",
      "\n",
      "[INFO] Training model for year 2003...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_2003.joblib\n",
      "\n",
      "[INFO] Training model for year 2004...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_2004.joblib\n",
      "\n",
      "[INFO] Training model for year 2005...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_2005.joblib\n",
      "\n",
      "[INFO] Training model for year 2006...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_2006.joblib\n",
      "\n",
      "[INFO] Training model for year 2007...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_2007.joblib\n",
      "\n",
      "[INFO] Training model for year 2008...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_2008.joblib\n",
      "\n",
      "[INFO] Training model for year 2009...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_2009.joblib\n",
      "\n",
      "[INFO] Training model for year 2010...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_2010.joblib\n",
      "\n",
      "[INFO] Training model for year 2011...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_2011.joblib\n",
      "\n",
      "[INFO] Training model for year 2012...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_2012.joblib\n",
      "\n",
      "[INFO] Training model for year 2013...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_2013.joblib\n",
      "\n",
      "[INFO] Training model for year 2014...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_2014.joblib\n",
      "\n",
      "[INFO] Training model for year 2015...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_2015.joblib\n",
      "\n",
      "[INFO] Training model for year 2016...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_2016.joblib\n",
      "\n",
      "[INFO] Training model for year 2017...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_2017.joblib\n",
      "\n",
      "[INFO] Training model for year 2018...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_2018.joblib\n",
      "\n",
      "[INFO] Training model for year 2019...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_2019.joblib\n",
      "\n",
      "[INFO] Training model for year 2020...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_2020.joblib\n",
      "\n",
      "[INFO] Training model for year 2021...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_2021.joblib\n",
      "\n",
      "[INFO] Training model for year 2022...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_2022.joblib\n",
      "\n",
      "[INFO] Training model for year 2023...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_2023.joblib\n",
      "\n",
      "[INFO] Training model for year 2024...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_2024.joblib\n",
      "\n",
      "[INFO] Training model for year 2025...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\checkpoints\\LogisticRegression_2025.joblib\n",
      "\n",
      "[DONE] Summary saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\summary_results.csv\n",
      "\n",
      "[INFO] Aggregating global metrics over all years:\n",
      "\n",
      "[SUMMARY] Recall@k (Top-k hit rate):\n",
      "Top-1 hit rate: 0.826 (38/46)\n",
      "Top-3 hit rate: 1.000 (46/46)\n",
      "Top-5 hit rate: 1.000 (46/46)\n",
      "Top-10 hit rate: 1.000 (46/46)\n",
      "\n",
      "[SUMMARY] Avg Precision@k vs real top-k:\n",
      "Precision@1 vs real top-1: 0.826\n",
      "Precision@3 vs real top-3: 0.739\n",
      "Precision@5 vs real top-5: 0.691\n",
      "Precision@10 vs real top-10: 0.725\n",
      "\n",
      "[SUMMARY] Avg Precision@k vs real top-10:\n",
      "Precision@1 vs real top-10: 1.000\n",
      "Precision@3 vs real top-10: 0.935\n",
      "Precision@5 vs real top-10: 0.874\n",
      "Precision@10 vs real top-10: 0.725\n",
      "\n",
      "[SUMMARY] Avg Mean Absolute Rank Error@k:\n",
      "Mean Abs Rank Error@1: 0.261\n",
      "Mean Abs Rank Error@3: 1.609\n",
      "Mean Abs Rank Error@5: 2.104\n",
      "Mean Abs Rank Error@10: 2.348\n",
      "\n",
      "[SUMMARY] True MVP rank statistics:\n",
      "Average rank: 1.28\n",
      "Min rank    : 1\n",
      "Max rank    : 3\n",
      "Correct MVP predictions (rank=1): 38/46\n",
      "[DONE] Mean summary saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\LogisticRegression_allStats_from1980\\mean_summary.csv\n",
      "\n",
      "[INFO] All selected pipelines finished.\n",
      "\n",
      "{'pipeline': ['all1980'], 'model': 'xgb', 'start': 1980, 'end': 2025, 'verbose': False, 'full': False, 'datasets_base_dir': 'c:\\\\Users\\\\cleme\\\\Eloi\\\\Code\\\\HoML\\\\Projet-Homl\\\\datasets', 'models_base_dir': 'c:\\\\Users\\\\cleme\\\\Eloi\\\\Code\\\\HoML\\\\Projet-Homl\\\\models', 'vprint': <function main.<locals>.<lambda> at 0x000001A76B5B23B0>, 'model_class': <class 'xgboost.sklearn.XGBClassifier'>, 'model_name': 'XGBClassifier', 'pipelines_to_run': ['all1980'], 'p': 'all1980', 'pipeline_key': 'all1980', 'pipeline_name': 'allStats_from1980', 'pipeline_min_year': 1980, 'frame': <frame at 0x000001A768C86240, file 'c:\\\\Users\\\\cleme\\\\Eloi\\\\Code\\\\HoML\\\\Projet-Homl\\\\train_models.py', line 502, code main>}\n",
      "[INFO] Running model 'XGBClassifier' on pipeline 'allStats_from1980' from 1980 to 2025...\n",
      "[INFO] Using hyperparameters: {'n_estimators': 100, 'learning_rate': 0.1, 'max_depth': 4, 'scale_pos_weight': 5, 'use_label_encoder': False, 'eval_metric': 'logloss', 'random_state': 42}\n",
      "\n",
      "[INFO] Training model for year 1980...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_1980.joblib\n",
      "\n",
      "[INFO] Training model for year 1981...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:44] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:44] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:44] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_1981.joblib\n",
      "\n",
      "[INFO] Training model for year 1982...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_1982.joblib\n",
      "\n",
      "[INFO] Training model for year 1983...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_1983.joblib\n",
      "\n",
      "[INFO] Training model for year 1984...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:44] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:44] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:44] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_1984.joblib\n",
      "\n",
      "[INFO] Training model for year 1985...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_1985.joblib\n",
      "\n",
      "[INFO] Training model for year 1986...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_1986.joblib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:44] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:44] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:44] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[INFO] Training model for year 1987...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_1987.joblib\n",
      "\n",
      "[INFO] Training model for year 1988...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_1988.joblib\n",
      "\n",
      "[INFO] Training model for year 1989...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:44] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:45] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:45] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_1989.joblib\n",
      "\n",
      "[INFO] Training model for year 1990...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_1990.joblib\n",
      "\n",
      "[INFO] Training model for year 1991...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_1991.joblib\n",
      "\n",
      "[INFO] Training model for year 1992...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:45] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:45] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:45] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_1992.joblib\n",
      "\n",
      "[INFO] Training model for year 1993...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_1993.joblib\n",
      "\n",
      "[INFO] Training model for year 1994...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_1994.joblib\n",
      "\n",
      "[INFO] Training model for year 1995...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:45] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:45] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:45] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_1995.joblib\n",
      "\n",
      "[INFO] Training model for year 1996...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_1996.joblib\n",
      "\n",
      "[INFO] Training model for year 1997...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_1997.joblib\n",
      "\n",
      "[INFO] Training model for year 1998...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:45] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:45] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:45] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_1998.joblib\n",
      "\n",
      "[INFO] Training model for year 1999...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_1999.joblib\n",
      "\n",
      "[INFO] Training model for year 2000...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_2000.joblib\n",
      "\n",
      "[INFO] Training model for year 2001...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:45] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:46] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:46] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_2001.joblib\n",
      "\n",
      "[INFO] Training model for year 2002...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_2002.joblib\n",
      "\n",
      "[INFO] Training model for year 2003...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_2003.joblib\n",
      "\n",
      "[INFO] Training model for year 2004...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:46] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:46] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:46] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_2004.joblib\n",
      "\n",
      "[INFO] Training model for year 2005...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_2005.joblib\n",
      "\n",
      "[INFO] Training model for year 2006...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_2006.joblib\n",
      "\n",
      "[INFO] Training model for year 2007...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:46] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:46] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:46] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_2007.joblib\n",
      "\n",
      "[INFO] Training model for year 2008...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_2008.joblib\n",
      "\n",
      "[INFO] Training model for year 2009...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_2009.joblib\n",
      "\n",
      "[INFO] Training model for year 2010...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:46] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:46] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:46] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_2010.joblib\n",
      "\n",
      "[INFO] Training model for year 2011...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_2011.joblib\n",
      "\n",
      "[INFO] Training model for year 2012...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_2012.joblib\n",
      "\n",
      "[INFO] Training model for year 2013...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:47] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:47] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:47] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_2013.joblib\n",
      "\n",
      "[INFO] Training model for year 2014...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_2014.joblib\n",
      "\n",
      "[INFO] Training model for year 2015...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_2015.joblib\n",
      "\n",
      "[INFO] Training model for year 2016...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:47] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:47] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:47] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_2016.joblib\n",
      "\n",
      "[INFO] Training model for year 2017...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_2017.joblib\n",
      "\n",
      "[INFO] Training model for year 2018...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_2018.joblib\n",
      "\n",
      "[INFO] Training model for year 2019...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:47] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:47] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:47] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_2019.joblib\n",
      "\n",
      "[INFO] Training model for year 2020...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_2020.joblib\n",
      "\n",
      "[INFO] Training model for year 2021...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_2021.joblib\n",
      "\n",
      "[INFO] Training model for year 2022...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:47] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:47] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n",
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:48] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_2022.joblib\n",
      "\n",
      "[INFO] Training model for year 2023...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_2023.joblib\n",
      "\n",
      "[INFO] Training model for year 2024...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_2024.joblib\n",
      "\n",
      "[INFO] Training model for year 2025...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\xgboost\\training.py:183: UserWarning: [18:17:48] WARNING: C:\\b\\abs_d97hy_84m6\\croot\\xgboost-split_1749630932152\\work\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\checkpoints\\XGBClassifier_2025.joblib\n",
      "\n",
      "[DONE] Summary saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\summary_results.csv\n",
      "\n",
      "[INFO] Aggregating global metrics over all years:\n",
      "\n",
      "[SUMMARY] Recall@k (Top-k hit rate):\n",
      "Top-1 hit rate: 0.826 (38/46)\n",
      "Top-3 hit rate: 0.870 (40/46)\n",
      "Top-5 hit rate: 0.913 (42/46)\n",
      "Top-10 hit rate: 0.978 (45/46)\n",
      "\n",
      "[SUMMARY] Avg Precision@k vs real top-k:\n",
      "Precision@1 vs real top-1: 0.826\n",
      "Precision@3 vs real top-3: 0.609\n",
      "Precision@5 vs real top-5: 0.622\n",
      "Precision@10 vs real top-10: 0.666\n",
      "\n",
      "[SUMMARY] Avg Precision@k vs real top-10:\n",
      "Precision@1 vs real top-10: 0.978\n",
      "Precision@3 vs real top-10: 0.899\n",
      "Precision@5 vs real top-10: 0.835\n",
      "Precision@10 vs real top-10: 0.666\n",
      "\n",
      "[SUMMARY] Avg Mean Absolute Rank Error@k:\n",
      "Mean Abs Rank Error@1: 0.739\n",
      "Mean Abs Rank Error@3: 2.188\n",
      "Mean Abs Rank Error@5: 2.826\n",
      "Mean Abs Rank Error@10: 2.857\n",
      "\n",
      "[SUMMARY] True MVP rank statistics:\n",
      "Average rank: 1.76\n",
      "Min rank    : 1\n",
      "Max rank    : 11\n",
      "Correct MVP predictions (rank=1): 38/46\n",
      "[DONE] Mean summary saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\XGBClassifier_allStats_from1980\\mean_summary.csv\n",
      "\n",
      "[INFO] All selected pipelines finished.\n",
      "\n",
      "{'pipeline': ['all1980'], 'model': 'rf', 'start': 1980, 'end': 2025, 'verbose': False, 'full': False, 'datasets_base_dir': 'c:\\\\Users\\\\cleme\\\\Eloi\\\\Code\\\\HoML\\\\Projet-Homl\\\\datasets', 'models_base_dir': 'c:\\\\Users\\\\cleme\\\\Eloi\\\\Code\\\\HoML\\\\Projet-Homl\\\\models', 'vprint': <function main.<locals>.<lambda> at 0x000001A76B5B2200>, 'model_class': <class 'sklearn.ensemble._forest.RandomForestClassifier'>, 'model_name': 'RandomForestClassifier', 'pipelines_to_run': ['all1980'], 'p': 'all1980', 'pipeline_key': 'all1980', 'pipeline_name': 'allStats_from1980', 'pipeline_min_year': 1980, 'frame': <frame at 0x000001A768C87F00, file 'c:\\\\Users\\\\cleme\\\\Eloi\\\\Code\\\\HoML\\\\Projet-Homl\\\\train_models.py', line 502, code main>}\n",
      "[INFO] Running model 'RandomForestClassifier' on pipeline 'allStats_from1980' from 1980 to 2025...\n",
      "[INFO] Using hyperparameters: {'n_estimators': 750, 'max_depth': 15, 'class_weight': None, 'min_samples_leaf': 2, 'random_state': 42}\n",
      "\n",
      "[INFO] Training model for year 1980...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_1980.joblib\n",
      "\n",
      "[INFO] Training model for year 1981...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_1981.joblib\n",
      "\n",
      "[INFO] Training model for year 1982...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_1982.joblib\n",
      "\n",
      "[INFO] Training model for year 1983...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_1983.joblib\n",
      "\n",
      "[INFO] Training model for year 1984...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_1984.joblib\n",
      "\n",
      "[INFO] Training model for year 1985...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_1985.joblib\n",
      "\n",
      "[INFO] Training model for year 1986...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_1986.joblib\n",
      "\n",
      "[INFO] Training model for year 1987...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_1987.joblib\n",
      "\n",
      "[INFO] Training model for year 1988...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_1988.joblib\n",
      "\n",
      "[INFO] Training model for year 1989...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_1989.joblib\n",
      "\n",
      "[INFO] Training model for year 1990...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_1990.joblib\n",
      "\n",
      "[INFO] Training model for year 1991...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_1991.joblib\n",
      "\n",
      "[INFO] Training model for year 1992...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_1992.joblib\n",
      "\n",
      "[INFO] Training model for year 1993...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_1993.joblib\n",
      "\n",
      "[INFO] Training model for year 1994...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_1994.joblib\n",
      "\n",
      "[INFO] Training model for year 1995...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_1995.joblib\n",
      "\n",
      "[INFO] Training model for year 1996...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_1996.joblib\n",
      "\n",
      "[INFO] Training model for year 1997...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_1997.joblib\n",
      "\n",
      "[INFO] Training model for year 1998...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_1998.joblib\n",
      "\n",
      "[INFO] Training model for year 1999...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_1999.joblib\n",
      "\n",
      "[INFO] Training model for year 2000...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_2000.joblib\n",
      "\n",
      "[INFO] Training model for year 2001...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_2001.joblib\n",
      "\n",
      "[INFO] Training model for year 2002...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_2002.joblib\n",
      "\n",
      "[INFO] Training model for year 2003...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_2003.joblib\n",
      "\n",
      "[INFO] Training model for year 2004...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_2004.joblib\n",
      "\n",
      "[INFO] Training model for year 2005...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_2005.joblib\n",
      "\n",
      "[INFO] Training model for year 2006...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_2006.joblib\n",
      "\n",
      "[INFO] Training model for year 2007...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_2007.joblib\n",
      "\n",
      "[INFO] Training model for year 2008...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_2008.joblib\n",
      "\n",
      "[INFO] Training model for year 2009...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_2009.joblib\n",
      "\n",
      "[INFO] Training model for year 2010...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_2010.joblib\n",
      "\n",
      "[INFO] Training model for year 2011...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_2011.joblib\n",
      "\n",
      "[INFO] Training model for year 2012...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_2012.joblib\n",
      "\n",
      "[INFO] Training model for year 2013...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_2013.joblib\n",
      "\n",
      "[INFO] Training model for year 2014...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_2014.joblib\n",
      "\n",
      "[INFO] Training model for year 2015...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_2015.joblib\n",
      "\n",
      "[INFO] Training model for year 2016...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_2016.joblib\n",
      "\n",
      "[INFO] Training model for year 2017...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_2017.joblib\n",
      "\n",
      "[INFO] Training model for year 2018...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_2018.joblib\n",
      "\n",
      "[INFO] Training model for year 2019...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_2019.joblib\n",
      "\n",
      "[INFO] Training model for year 2020...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_2020.joblib\n",
      "\n",
      "[INFO] Training model for year 2021...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_2021.joblib\n",
      "\n",
      "[INFO] Training model for year 2022...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_2022.joblib\n",
      "\n",
      "[INFO] Training model for year 2023...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_2023.joblib\n",
      "\n",
      "[INFO] Training model for year 2024...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_2024.joblib\n",
      "\n",
      "[INFO] Training model for year 2025...\n",
      "[DONE] Model saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\checkpoints\\RandomForestClassifier_2025.joblib\n",
      "\n",
      "[DONE] Summary saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\summary_results.csv\n",
      "\n",
      "[INFO] Aggregating global metrics over all years:\n",
      "\n",
      "[SUMMARY] Recall@k (Top-k hit rate):\n",
      "Top-1 hit rate: 0.717 (33/46)\n",
      "Top-3 hit rate: 0.935 (43/46)\n",
      "Top-5 hit rate: 0.957 (44/46)\n",
      "Top-10 hit rate: 1.000 (46/46)\n",
      "\n",
      "[SUMMARY] Avg Precision@k vs real top-k:\n",
      "Precision@1 vs real top-1: 0.717\n",
      "Precision@3 vs real top-3: 0.623\n",
      "Precision@5 vs real top-5: 0.565\n",
      "Precision@10 vs real top-10: 0.596\n",
      "\n",
      "[SUMMARY] Avg Precision@k vs real top-10:\n",
      "Precision@1 vs real top-10: 1.000\n",
      "Precision@3 vs real top-10: 0.891\n",
      "Precision@5 vs real top-10: 0.796\n",
      "Precision@10 vs real top-10: 0.596\n",
      "\n",
      "[SUMMARY] Avg Mean Absolute Rank Error@k:\n",
      "Mean Abs Rank Error@1: 0.978\n",
      "Mean Abs Rank Error@3: 2.514\n",
      "Mean Abs Rank Error@5: 3.139\n",
      "Mean Abs Rank Error@10: 3.104\n",
      "\n",
      "[SUMMARY] True MVP rank statistics:\n",
      "Average rank: 1.61\n",
      "Min rank    : 1\n",
      "Max rank    : 6\n",
      "Correct MVP predictions (rank=1): 33/46\n",
      "[DONE] Mean summary saved to c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\models\\RandomForestClassifier_allStats_from1980\\mean_summary.csv\n",
      "\n",
      "[INFO] All selected pipelines finished.\n"
     ]
    }
   ],
   "source": [
    "models=[\"logreg\", \"xgb\", \"rf\"]\n",
    "for model in models:\n",
    "    t.main(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7b64ba",
   "metadata": {},
   "source": [
    "# IV. Optimization : feature selection and hyperparameter tuning. \n",
    "\n",
    "\n",
    "## A. Feature selection\n",
    "\n",
    "We have implemented to ways of doing feature selection : forward greedy selection and backward greedy selection. We applied them both to logistic regression, random forest and xgb in order to find a better set of feature to train the models on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "941439c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running greedy forward for pipeline: allStats_from1980\n",
      "[INFO] Running greedy forward selection (Recall@1) on dataset: c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\datasets\\allStats_from1980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Added feature 1 | Total: 1 | Recall@1: 0.283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Added feature 26 | Total: 2 | Recall@1: 0.587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Added feature 25 | Total: 3 | Recall@1: 0.652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Added feature 18 | Total: 4 | Recall@1: 0.674\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                              \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#greedy forward feature selection \u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mgf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mall1980\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogreg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\hyperparameters_tuning\\greedy_forward_feature_selection.py:131\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(pipelines, model, patience)\u001b[0m\n\u001b[0;32m    127\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(output_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    129\u001b[0m     fixed_params \u001b[38;5;241m=\u001b[39m get_default_hyperparams(model_class, pipeline_name)\n\u001b[1;32m--> 131\u001b[0m     \u001b[43mgreedy_forward_selection\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipeline_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfixed_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    132\u001b[0m \u001b[43m                             \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[DONE] All greedy forward runs completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\hyperparameters_tuning\\greedy_forward_feature_selection.py:40\u001b[0m, in \u001b[0;36mgreedy_forward_selection\u001b[1;34m(model_class, dataset_dir, pipeline_name, fixed_params, output_dir, year_start, year_end, patience)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feat \u001b[38;5;129;01min\u001b[39;00m tqdm(available_features, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting additions (current=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(selected_features)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     39\u001b[0m     candidate \u001b[38;5;241m=\u001b[39m selected_features \u001b[38;5;241m+\u001b[39m [feat]\n\u001b[1;32m---> 40\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_recall_at_1_avg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfixed_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcandidate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m score \u001b[38;5;241m>\u001b[39m current_best_score \u001b[38;5;129;01mor\u001b[39;00m (score \u001b[38;5;241m==\u001b[39m current_best_score \u001b[38;5;129;01mand\u001b[39;00m feat \u001b[38;5;241m<\u001b[39m (feature_to_add \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m))):\n\u001b[0;32m     42\u001b[0m         current_best_score \u001b[38;5;241m=\u001b[39m score\n",
      "File \u001b[1;32mc:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\hyperparameters_tuning\\feature_selection.py:39\u001b[0m, in \u001b[0;36mcompute_recall_at_1_avg\u001b[1;34m(model_class, fixed_params, dataset_dir, start_year, end_year, feature_indices)\u001b[0m\n\u001b[0;32m     36\u001b[0m player_names \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName_test\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     38\u001b[0m model \u001b[38;5;241m=\u001b[39m model_class(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfixed_params)\n\u001b[1;32m---> 39\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m results \u001b[38;5;241m=\u001b[39m evaluate_model(model, X_test, y_test, y10_test, player_names, top_ks\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     41\u001b[0m recalls\u001b[38;5;241m.\u001b[39mappend(results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_1_hit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\sklearn\\base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1363\u001b[0m     )\n\u001b[0;32m   1364\u001b[0m ):\n\u001b[1;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1384\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1382\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1384\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1387\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1390\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1394\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1405\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1406\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1407\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1409\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1410\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     73\u001b[0m warning_filters \u001b[38;5;241m=\u001b[39m warnings\u001b[38;5;241m.\u001b[39mfilters\n\u001b[0;32m     74\u001b[0m iterable_with_config_and_warning_filters \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     75\u001b[0m     (\n\u001b[0;32m     76\u001b[0m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     81\u001b[0m )\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\joblib\\parallel.py:1986\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1984\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1985\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1986\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1988\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1989\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1990\u001b[0m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1991\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1992\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1993\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\joblib\\parallel.py:1914\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1912\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1913\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1914\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1916\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig), warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m    146\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilters \u001b[38;5;241m=\u001b[39m warning_filters\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:560\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[0;32m    557\u001b[0m         alpha \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m C) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m l1_ratio)\n\u001b[0;32m    558\u001b[0m         beta \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m C) \u001b[38;5;241m*\u001b[39m l1_ratio\n\u001b[1;32m--> 560\u001b[0m     w0, n_iter_i, warm_start_sag \u001b[38;5;241m=\u001b[39m \u001b[43msag_solver\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    561\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarm_start_sag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_saga\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msolver must be one of \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewton-cg\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m}, got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m solver\n\u001b[0;32m    581\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:323\u001b[0m, in \u001b[0;36msag_solver\u001b[1;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mZeroDivisionError\u001b[39;00m(\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent sag implementation does not handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe case step_size * alpha_scaled == 1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m     )\n\u001b[0;32m    322\u001b[0m sag \u001b[38;5;241m=\u001b[39m sag64 \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64 \u001b[38;5;28;01melse\u001b[39;00m sag32\n\u001b[1;32m--> 323\u001b[0m num_seen, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43msag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43msum_gradient_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_memory_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseen_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_seen_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept_sum_gradient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_saga\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_iter_ \u001b[38;5;241m==\u001b[39m max_iter:\n\u001b[0;32m    348\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    349\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe max_iter was reached which means the coef_ did not converge\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    350\u001b[0m         ConvergenceWarning,\n\u001b[0;32m    351\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#greedy forward feature selection \n",
    "\n",
    "gf.main([\"all1980\"],  \"logreg\", 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34e3c485",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Running greedy backward RFE for pipeline: allStats_from1980\n",
      "[INFO] Running greedy backward RFE (Recall@1) on dataset: c:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\datasets\\allStats_from1980\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#greedy backward feature selection\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[43mgb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mall1980\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogreg\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\hyperparameters_tuning\\greedy_backward_feature_selection.py:147\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(pipelines, model, patience)\u001b[0m\n\u001b[0;32m    143\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(output_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    145\u001b[0m     fixed_params \u001b[38;5;241m=\u001b[39m get_default_hyperparams(model_class, pipeline_name)\n\u001b[1;32m--> 147\u001b[0m     \u001b[43mgreedy_backward_rfe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpipeline_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfixed_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    148\u001b[0m \u001b[43m                        \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpatience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpatience\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m[DONE] All greedy backward RFE runs completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\hyperparameters_tuning\\greedy_backward_feature_selection.py:56\u001b[0m, in \u001b[0;36mgreedy_backward_rfe\u001b[1;34m(model_class, dataset_dir, pipeline_name, fixed_params, output_dir, year_start, year_end, patience)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m feat \u001b[38;5;129;01min\u001b[39;00m tqdm(remaining_features, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTesting removal candidates (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m feats)\u001b[39m\u001b[38;5;124m\"\u001b[39m, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m     55\u001b[0m     candidate \u001b[38;5;241m=\u001b[39m [f \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m remaining_features \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;241m!=\u001b[39m feat]\n\u001b[1;32m---> 56\u001b[0m     score \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_recall_at_1_avg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfixed_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdataset_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43myear_end\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcandidate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m score \u001b[38;5;241m>\u001b[39m current_best_score \u001b[38;5;129;01mor\u001b[39;00m (score \u001b[38;5;241m==\u001b[39m current_best_score \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(candidate) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(remaining_features)):\n\u001b[0;32m     58\u001b[0m         current_best_score \u001b[38;5;241m=\u001b[39m score\n",
      "File \u001b[1;32mc:\\Users\\cleme\\Eloi\\Code\\HoML\\Projet-Homl\\hyperparameters_tuning\\feature_selection.py:39\u001b[0m, in \u001b[0;36mcompute_recall_at_1_avg\u001b[1;34m(model_class, fixed_params, dataset_dir, start_year, end_year, feature_indices)\u001b[0m\n\u001b[0;32m     36\u001b[0m player_names \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mName_test\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m     38\u001b[0m model \u001b[38;5;241m=\u001b[39m model_class(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfixed_params)\n\u001b[1;32m---> 39\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m results \u001b[38;5;241m=\u001b[39m evaluate_model(model, X_test, y_test, y10_test, player_names, top_ks\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m])\n\u001b[0;32m     41\u001b[0m recalls\u001b[38;5;241m.\u001b[39mappend(results[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtop_1_hit\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\sklearn\\base.py:1365\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1358\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1360\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1361\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1362\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1363\u001b[0m     )\n\u001b[0;32m   1364\u001b[0m ):\n\u001b[1;32m-> 1365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1384\u001b[0m, in \u001b[0;36mLogisticRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1381\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1382\u001b[0m     n_threads \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1384\u001b[0m fold_coefs_ \u001b[38;5;241m=\u001b[39m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprefer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1385\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1386\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1387\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1388\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpos_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1389\u001b[0m \u001b[43m        \u001b[49m\u001b[43mCs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mC_\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1390\u001b[0m \u001b[43m        \u001b[49m\u001b[43ml1_ratio\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43ml1_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1391\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1392\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1393\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1394\u001b[0m \u001b[43m        \u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msolver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1395\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmulti_class\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmulti_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1396\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1397\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclass_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclass_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1398\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheck_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1399\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1400\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcoef\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1401\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpenalty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpenalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1402\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1403\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1404\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1405\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1406\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclass_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mclasses_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwarm_start_coef\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1407\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1409\u001b[0m fold_coefs_, _, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39mfold_coefs_)\n\u001b[0;32m   1410\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_iter_ \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(n_iter_, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mint32)[:, \u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\sklearn\\utils\\parallel.py:82\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     73\u001b[0m warning_filters \u001b[38;5;241m=\u001b[39m warnings\u001b[38;5;241m.\u001b[39mfilters\n\u001b[0;32m     74\u001b[0m iterable_with_config_and_warning_filters \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     75\u001b[0m     (\n\u001b[0;32m     76\u001b[0m         _with_config_and_warning_filters(delayed_func, config, warning_filters),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     80\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     81\u001b[0m )\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config_and_warning_filters\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\joblib\\parallel.py:1986\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1984\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1985\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1986\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1988\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1989\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1990\u001b[0m \u001b[38;5;66;03m# reused, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1991\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1992\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1993\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\joblib\\parallel.py:1914\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1912\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1913\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1914\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1915\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1916\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\sklearn\\utils\\parallel.py:147\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig), warnings\u001b[38;5;241m.\u001b[39mcatch_warnings():\n\u001b[0;32m    146\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mfilters \u001b[38;5;241m=\u001b[39m warning_filters\n\u001b[1;32m--> 147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:560\u001b[0m, in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio, n_threads)\u001b[0m\n\u001b[0;32m    557\u001b[0m         alpha \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m C) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m l1_ratio)\n\u001b[0;32m    558\u001b[0m         beta \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m/\u001b[39m C) \u001b[38;5;241m*\u001b[39m l1_ratio\n\u001b[1;32m--> 560\u001b[0m     w0, n_iter_i, warm_start_sag \u001b[38;5;241m=\u001b[39m \u001b[43msag_solver\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    561\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    562\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    563\u001b[0m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    564\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    565\u001b[0m \u001b[43m        \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    568\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    570\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    571\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    572\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_squared_sum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    573\u001b[0m \u001b[43m        \u001b[49m\u001b[43mwarm_start_sag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    574\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_saga\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msaga\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    575\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    579\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msolver must be one of \u001b[39m\u001b[38;5;124m{\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mliblinear\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlbfgs\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    580\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnewton-cg\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msag\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m}, got \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m solver\n\u001b[0;32m    581\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\cleme\\miniconda3\\envs\\nba-mvp-prediction\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:323\u001b[0m, in \u001b[0;36msag_solver\u001b[1;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mZeroDivisionError\u001b[39;00m(\n\u001b[0;32m    318\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCurrent sag implementation does not handle \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe case step_size * alpha_scaled == 1\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m     )\n\u001b[0;32m    322\u001b[0m sag \u001b[38;5;241m=\u001b[39m sag64 \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m np\u001b[38;5;241m.\u001b[39mfloat64 \u001b[38;5;28;01melse\u001b[39;00m sag32\n\u001b[1;32m--> 323\u001b[0m num_seen, n_iter_ \u001b[38;5;241m=\u001b[39m \u001b[43msag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    325\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    326\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    327\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    328\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn_classes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    331\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstep_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43malpha_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta_scaled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[43msum_gradient_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgradient_memory_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    338\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseen_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mnum_seen_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    340\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfit_intercept\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept_sum_gradient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mintercept_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_saga\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    345\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n_iter_ \u001b[38;5;241m==\u001b[39m max_iter:\n\u001b[0;32m    348\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    349\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe max_iter was reached which means the coef_ did not converge\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    350\u001b[0m         ConvergenceWarning,\n\u001b[0;32m    351\u001b[0m     )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#greedy backward feature selection\n",
    "\n",
    "gb.main([\"all1980\"],  \"logreg\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24cb0bca",
   "metadata": {},
   "source": [
    "## B. Hyperparameter Tuning.\n",
    "\n",
    "We chose to tune the hyperparameters of the xgb, Logistic Regression and Random Forest, because these were the models that gave the best results when trained and evaluated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20346131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Using param values for 'C': [1, 2, 3, 4, 5]\n",
      "\n",
      "\n",
      "#########################\n",
      "## Pipeline: allStats_from1980\n",
      "#########################\n",
      "\n",
      "\n",
      "[INFO] Tuning 'C' on pipeline 'allStats_from1980' [1980-2025]\n",
      "\n",
      "\n",
      "=== Testing C = 1 ===\n",
      "\n",
      "C=1: 100%|██████████| 46/46 [00:42<00:00,  1.08it/s]\n",
      "\n",
      "=== Testing C = 2 ===\n",
      "\n",
      "C=2: 100%|██████████| 46/46 [00:47<00:00,  1.04s/it]\n",
      "\n",
      "=== Testing C = 3 ===\n",
      "\n",
      "C=3: 100%|██████████| 46/46 [00:57<00:00,  1.25s/it]\n",
      "\n",
      "=== Testing C = 4 ===\n",
      "\n",
      "C=4: 100%|██████████| 46/46 [00:52<00:00,  1.15s/it]\n",
      "\n",
      "=== Testing C = 5 ===\n",
      "\n",
      "C=5: 100%|██████████| 46/46 [01:13<00:00,  1.60s/it]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ht.main(\"logreg\", \"C\", [1, 2, 3, 4, 5], combo={}, full=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0347bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nba-mvp-prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
